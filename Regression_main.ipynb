{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0849b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c628bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c94ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bdf38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
       "0             619    France       0  ...               1        101348.88       1\n",
       "1             608     Spain       0  ...               1        112542.58       0\n",
       "2             502    France       0  ...               0        113931.57       1\n",
       "3             699    France       0  ...               0         93826.63       0\n",
       "4             850     Spain       0  ...               1         79084.10       0\n",
       "...           ...       ...     ...  ...             ...              ...     ...\n",
       "9995          771    France       1  ...               0         96270.64       0\n",
       "9996          516    France       1  ...               1        101699.77       0\n",
       "9997          709    France       0  ...               1         42085.58       1\n",
       "9998          772   Germany       1  ...               0         92888.52       1\n",
       "9999          792    France       0  ...               0         38190.78       0\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0745148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Geography_France  Geography_Germany  Geography_Spain\n",
       "0                  1.0                0.0              0.0\n",
       "1                  0.0                0.0              1.0\n",
       "2                  1.0                0.0              0.0\n",
       "3                  1.0                0.0              0.0\n",
       "4                  0.0                0.0              1.0\n",
       "...                ...                ...              ...\n",
       "9995               1.0                0.0              0.0\n",
       "9996               1.0                0.0              0.0\n",
       "9997               1.0                0.0              0.0\n",
       "9998               0.0                1.0              0.0\n",
       "9999               1.0                0.0              0.0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoder_geography = OneHotEncoder(handle_unknown='ignore')\n",
    "geography_encoded = onehot_encoder_geography.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geography_encoded , columns=onehot_encoder_geography.get_feature_names_out(['Geography']))\n",
    "geo_encoded_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af26a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  ...  Geography_Germany  Geography_Spain\n",
       "0          619       0  ...                0.0              0.0\n",
       "1          608       0  ...                0.0              1.0\n",
       "2          502       0  ...                0.0              0.0\n",
       "3          699       0  ...                0.0              0.0\n",
       "4          850       0  ...                0.0              1.0\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinrg the encoded geography with the original data\n",
    "data = pd.concat([data.drop('Geography',axis=1), geo_encoded_df], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38c90b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into features and target variable\n",
    "X = data.drop('EstimatedSalary', axis=1)\n",
    "y = data['EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e37ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5812c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2684ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the encoder and scaler \n",
    "with open('label_encoder_gender.pkl', 'wb') as f:    \n",
    "    pickle.dump(label_encoder_gender,f)\n",
    "\n",
    "with open('onehot_encoder_geography.pkl', 'wb') as f:\n",
    "          pickle.dump(onehot_encoder_geography, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44b9cae",
   "metadata": {},
   "source": [
    "# ANN REGRESSION IMPLEMENTAION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e63468f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping , TensorBoard\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "886b417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 18:45:52.569647: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-07-02 18:45:52.569909: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-07-02 18:45:52.570490: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-07-02 18:45:52.570611: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-07-02 18:45:52.571149: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model\n",
    "model = Sequential([\n",
    "          Dense(64, activation='relu', input_shape=(X_train.shape[1],)), ## HL1 connected to input layer\n",
    "          Dense(32, activation='relu'),  ## HL2 connected to HL1\n",
    "          Dense(1)  ## Output layer\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer = 'adam' , loss = \"mean_absolute_error\" , metrics = ['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4adcfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the tensorboard\n",
    "log_dir = \"regressionlogs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorflow_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b109e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4919d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 18:47:45.709931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/250 [===========================>..] - ETA: 0s - loss: 100462.1406 - mae: 100462.1406"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 18:47:48.263241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 3s 5ms/step - loss: 100425.3203 - mae: 100425.3203 - val_loss: 98704.4219 - val_mae: 98704.4219\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 100370.6797 - mae: 100370.6797 - val_loss: 98612.7266 - val_mae: 98612.7266\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 100263.8125 - mae: 100263.8125 - val_loss: 98480.1953 - val_mae: 98480.1953\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 100152.3906 - mae: 100152.3906 - val_loss: 98375.1094 - val_mae: 98375.1094\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 100078.1953 - mae: 100078.1953 - val_loss: 98276.0938 - val_mae: 98276.0938\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 99980.1328 - mae: 99980.1328 - val_loss: 98154.3828 - val_mae: 98154.3828\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 99829.6484 - mae: 99829.6484 - val_loss: 97982.6797 - val_mae: 97982.6797\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 99613.9531 - mae: 99613.9531 - val_loss: 97755.6484 - val_mae: 97755.6484\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 99347.1406 - mae: 99347.1406 - val_loss: 97535.6016 - val_mae: 97535.6016\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 99109.1719 - mae: 99109.1719 - val_loss: 97328.9141 - val_mae: 97328.9141\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 98893.7344 - mae: 98893.7344 - val_loss: 97140.4766 - val_mae: 97140.4766\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 98694.3125 - mae: 98694.3125 - val_loss: 96958.4922 - val_mae: 96958.4922\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 98497.8516 - mae: 98497.8516 - val_loss: 96772.4609 - val_mae: 96772.4609\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 98302.3047 - mae: 98302.3047 - val_loss: 96557.9297 - val_mae: 96557.9297\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 98096.2578 - mae: 98096.2578 - val_loss: 96348.1484 - val_mae: 96348.1484\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 97894.5547 - mae: 97894.5547 - val_loss: 96141.6094 - val_mae: 96141.6094\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 97669.4375 - mae: 97669.4375 - val_loss: 95897.5312 - val_mae: 95897.5312\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 97450.3984 - mae: 97450.3984 - val_loss: 95667.5547 - val_mae: 95667.5547\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 97222.0312 - mae: 97222.0312 - val_loss: 95430.1484 - val_mae: 95430.1484\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 96980.0469 - mae: 96980.0469 - val_loss: 95173.1797 - val_mae: 95173.1797\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 96745.3047 - mae: 96745.3047 - val_loss: 94929.6406 - val_mae: 94929.6406\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 96509.1562 - mae: 96509.1562 - val_loss: 94690.4375 - val_mae: 94690.4375\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 96257.7891 - mae: 96257.7891 - val_loss: 94443.9062 - val_mae: 94443.9062\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 96008.2891 - mae: 96008.2891 - val_loss: 94201.3125 - val_mae: 94201.3125\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 95756.9688 - mae: 95756.9688 - val_loss: 93928.4453 - val_mae: 93928.4453\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 95493.2344 - mae: 95493.2344 - val_loss: 93674.6875 - val_mae: 93674.6875\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 95238.7812 - mae: 95238.7812 - val_loss: 93433.2969 - val_mae: 93433.2969\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 94979.0312 - mae: 94979.0312 - val_loss: 93147.8594 - val_mae: 93147.8594\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 94702.7969 - mae: 94702.7969 - val_loss: 92858.8203 - val_mae: 92858.8203\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 94424.1797 - mae: 94424.1797 - val_loss: 92622.1562 - val_mae: 92622.1562\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 94161.4688 - mae: 94161.4688 - val_loss: 92339.1719 - val_mae: 92339.1719\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 93898.7422 - mae: 93898.7422 - val_loss: 92026.5938 - val_mae: 92026.5938\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 93607.9609 - mae: 93607.9609 - val_loss: 91759.6797 - val_mae: 91759.6797\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 93321.9062 - mae: 93321.9062 - val_loss: 91461.6172 - val_mae: 91461.6172\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 93034.8594 - mae: 93034.8594 - val_loss: 91192.9531 - val_mae: 91192.9531\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 92724.6250 - mae: 92724.6250 - val_loss: 90889.6250 - val_mae: 90889.6250\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 92444.9062 - mae: 92444.9062 - val_loss: 90582.1172 - val_mae: 90582.1172\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 92142.8672 - mae: 92142.8672 - val_loss: 90326.0156 - val_mae: 90326.0156\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 91822.9219 - mae: 91822.9219 - val_loss: 89959.0234 - val_mae: 89959.0234\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 91523.2812 - mae: 91523.2812 - val_loss: 89746.5078 - val_mae: 89746.5078\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 91241.9453 - mae: 91241.9453 - val_loss: 89335.6953 - val_mae: 89335.6953\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 90897.2109 - mae: 90897.2109 - val_loss: 89039.5547 - val_mae: 89039.5547\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 90598.8828 - mae: 90598.8828 - val_loss: 88711.4844 - val_mae: 88711.4844\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 90291.5703 - mae: 90291.5703 - val_loss: 88396.6875 - val_mae: 88396.6875\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 89959.1172 - mae: 89959.1172 - val_loss: 88109.0312 - val_mae: 88109.0312\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 89627.7188 - mae: 89627.7188 - val_loss: 87745.1562 - val_mae: 87745.1562\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 89335.7812 - mae: 89335.7812 - val_loss: 87454.6953 - val_mae: 87454.6953\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 88996.3516 - mae: 88996.3516 - val_loss: 87150.5312 - val_mae: 87150.5312\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 88662.3203 - mae: 88662.3203 - val_loss: 86755.5469 - val_mae: 86755.5469\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 88324.7812 - mae: 88324.7812 - val_loss: 86522.1172 - val_mae: 86522.1172\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 87998.1797 - mae: 87998.1797 - val_loss: 86109.0391 - val_mae: 86109.0391\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 87662.4141 - mae: 87662.4141 - val_loss: 85759.6797 - val_mae: 85759.6797\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 87317.2266 - mae: 87317.2266 - val_loss: 85408.3281 - val_mae: 85408.3281\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 86979.4141 - mae: 86979.4141 - val_loss: 85114.6172 - val_mae: 85114.6172\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 86640.9297 - mae: 86640.9297 - val_loss: 84720.5625 - val_mae: 84720.5625\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 86292.9531 - mae: 86292.9531 - val_loss: 84461.9062 - val_mae: 84461.9062\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 85905.6094 - mae: 85905.6094 - val_loss: 84281.3906 - val_mae: 84281.3906\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 85619.5781 - mae: 85619.5781 - val_loss: 83668.6172 - val_mae: 83668.6172\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 85211.9844 - mae: 85211.9844 - val_loss: 83376.9375 - val_mae: 83376.9375\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 84872.4766 - mae: 84872.4766 - val_loss: 82967.5547 - val_mae: 82967.5547\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 84505.2656 - mae: 84505.2656 - val_loss: 82621.1562 - val_mae: 82621.1562\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 84182.8438 - mae: 84182.8438 - val_loss: 82248.4531 - val_mae: 82248.4531\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 83783.7656 - mae: 83783.7656 - val_loss: 81984.6016 - val_mae: 81984.6016\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 83418.2344 - mae: 83418.2344 - val_loss: 81527.9297 - val_mae: 81527.9297\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 83058.6797 - mae: 83058.6797 - val_loss: 81155.8750 - val_mae: 81155.8750\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 82670.5234 - mae: 82670.5234 - val_loss: 80789.4922 - val_mae: 80789.4922\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 82276.8828 - mae: 82276.8828 - val_loss: 80618.3984 - val_mae: 80618.3984\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 81931.4688 - mae: 81931.4688 - val_loss: 80095.8281 - val_mae: 80095.8281\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 81548.2734 - mae: 81548.2734 - val_loss: 79713.5703 - val_mae: 79713.5703\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 81168.0703 - mae: 81168.0703 - val_loss: 79286.3594 - val_mae: 79286.3594\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 80789.8594 - mae: 80789.8594 - val_loss: 78906.6016 - val_mae: 78906.6016\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 80383.6172 - mae: 80383.6172 - val_loss: 78520.4219 - val_mae: 78520.4219\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 80030.3359 - mae: 80030.3359 - val_loss: 78203.6641 - val_mae: 78203.6641\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 79655.2812 - mae: 79655.2812 - val_loss: 77790.0703 - val_mae: 77790.0703\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 79275.9453 - mae: 79275.9453 - val_loss: 77529.8203 - val_mae: 77529.8203\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 78903.2578 - mae: 78903.2578 - val_loss: 76990.8281 - val_mae: 76990.8281\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 78487.3125 - mae: 78487.3125 - val_loss: 76602.9609 - val_mae: 76602.9609\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 78079.2578 - mae: 78079.2578 - val_loss: 76457.1016 - val_mae: 76457.1016\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 77791.9922 - mae: 77791.9922 - val_loss: 75840.0234 - val_mae: 75840.0234\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 77296.0547 - mae: 77296.0547 - val_loss: 75609.9922 - val_mae: 75609.9922\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 76895.3047 - mae: 76895.3047 - val_loss: 75087.5078 - val_mae: 75087.5078\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 76519.8672 - mae: 76519.8672 - val_loss: 74671.3594 - val_mae: 74671.3594\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 76161.0469 - mae: 76161.0469 - val_loss: 74378.3438 - val_mae: 74378.3438\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 75773.0547 - mae: 75773.0547 - val_loss: 74001.8281 - val_mae: 74001.8281\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 75334.4453 - mae: 75334.4453 - val_loss: 73752.1484 - val_mae: 73752.1484\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 74957.1719 - mae: 74957.1719 - val_loss: 73380.6875 - val_mae: 73380.6875\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 74619.6094 - mae: 74619.6094 - val_loss: 72746.3516 - val_mae: 72746.3516\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 74181.3906 - mae: 74181.3906 - val_loss: 72356.5469 - val_mae: 72356.5469\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 73808.7891 - mae: 73808.7891 - val_loss: 71980.3047 - val_mae: 71980.3047\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 73335.9922 - mae: 73335.9922 - val_loss: 71624.1406 - val_mae: 71624.1406\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 72996.5625 - mae: 72996.5625 - val_loss: 71597.8438 - val_mae: 71597.8438\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 72599.1250 - mae: 72599.1250 - val_loss: 70818.0156 - val_mae: 70818.0156\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 72167.1016 - mae: 72167.1016 - val_loss: 70431.1484 - val_mae: 70431.1484\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 71810.7109 - mae: 71810.7109 - val_loss: 70518.5703 - val_mae: 70518.5703\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 71385.7500 - mae: 71385.7500 - val_loss: 70018.4922 - val_mae: 70018.4922\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 71005.7031 - mae: 71005.7031 - val_loss: 69375.2266 - val_mae: 69375.2266\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 70582.6797 - mae: 70582.6797 - val_loss: 68879.7812 - val_mae: 68879.7812\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 70181.3672 - mae: 70181.3672 - val_loss: 68623.3125 - val_mae: 68623.3125\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 69850.0703 - mae: 69850.0703 - val_loss: 68099.6094 - val_mae: 68099.6094\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 69389.7578 - mae: 69389.7578 - val_loss: 67764.2344 - val_mae: 67764.2344\n"
     ]
    }
   ],
   "source": [
    "## Train the Model\n",
    "history = model.fit(\n",
    "          X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=100 , \n",
    "          callbacks = [tensorflow_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f146077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b7317c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 22800), started 0:00:09 ago. (Use '!kill 22800' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-997fbac42f759617\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-997fbac42f759617\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir regressionlogs/fit --port 6007\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ac0fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syedmaaz/MAIN/STUDY/Projects/ANN Churn Classification Deep Learning/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02aabfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
